{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e8871c87-3e58-4abb-9dc8-1041537ffc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d65e332-062b-44c0-9dc8-3e20b1717d15",
   "metadata": {},
   "source": [
    "## Building the 1D-CNN with residual connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "43f905e2-1ad6-412b-83ed-fc258a34e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # First conv layer\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels, \n",
    "            out_channels, \n",
    "            kernel_size=3, \n",
    "            stride=stride, \n",
    "            padding=1\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        # Second conv layer\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            out_channels, \n",
    "            out_channels, \n",
    "            kernel_size=3, \n",
    "            stride=1, \n",
    "            padding=1\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        # If we change channels or stride, we need to adjust the skip path\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x  # save original input for skip connection\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        # Adjust identity if needed\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "        \n",
    "        # Add skip connection\n",
    "        out = out + identity\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2df5c6dc-44e8-4e92-ab6d-4e5966efbf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet1D(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initial convolution \"stem\"\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=n_channels,\n",
    "            out_channels=64,\n",
    "            kernel_size=7,\n",
    "            stride=2,\n",
    "            padding=3\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Residual stages\n",
    "        self.layer1 = self._make_layer(64, 64, num_blocks=2, stride=1)\n",
    "        self.layer2 = self._make_layer(64, 128, num_blocks=2, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, num_blocks=2, stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512, num_blocks=2, stride=2)\n",
    "        \n",
    "        # Global average pooling over time dimension\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)  # output: (batch, channels, 1)\n",
    "        \n",
    "        # Final classifier\n",
    "        self.fc = nn.Linear(512, n_classes)\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "        # First block may change channels/stride\n",
    "        layers.append(ResidualBlock1D(in_channels, out_channels, stride=stride))\n",
    "        # Remaining blocks keep same channels/stride=1\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(ResidualBlock1D(out_channels, out_channels, stride=1))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, n_channels, n_times)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        # Residual layers\n",
    "        x = self.layer1(x)  # shape: (batch, 64, T1)\n",
    "        x = self.layer2(x)  # shape: (batch, 128, T2)\n",
    "        x = self.layer3(x)  # shape: (batch, 256, T3)\n",
    "        x = self.layer4(x)  # shape: (batch, 512, T4)\n",
    "        \n",
    "        # Global average pooling: average over time dimension\n",
    "        x = self.global_pool(x)  # (batch, 512, 1)\n",
    "        x = x.squeeze(-1)        # (batch, 512)\n",
    "        \n",
    "        # Classifier\n",
    "        logits = self.fc(x)      # (batch, n_classes)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cb72a7bc-60e4-4feb-bdf0-f5ed370e90d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialze the CNN\n",
    "\n",
    "n_channels = 32      # or however many EEG channels we have\n",
    "n_classes = 2        # ADHD vs Control\n",
    "\n",
    "model = ResNet1D(n_channels=n_channels, n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7ac935-d22c-4a3f-9620-faf71cb04d70",
   "metadata": {},
   "source": [
    "## Building the training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "99dd283f-4d57-49e7-af87-0930a2cc895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset class\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X.float()\n",
    "        self.y = y.long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "40692463-afd7-4c4e-92f3-0c9328b2797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and Y based on subjects \n",
    "X_raw = np.load(\"../data/X_tqwt_wpd.npy\")\n",
    "y_raw = np.load(\"../data/y_labels.npy\")\n",
    "subject_ids = np.load(\"../data/subject_ids.npy\", allow_pickle=True)\n",
    "\n",
    "unique_subs = np.unique(subject_ids)\n",
    "# Not required \n",
    "#print(\"Number of subjects:\", len(unique_subs))\n",
    "#print(\"Subject IDs:\", unique_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5690d141-40d0-4331-8883-4776b3580e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = np.isin(subject_ids, X_raw)\n",
    "val_mask = np.isin(subject_ids, y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b08355-f8a0-4f6a-a63e-ec74e6da25c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to torch tensors\n",
    "X = X[train_mask]\n",
    "y = y[train_mask]\n",
    "\n",
    "X_val_np = X[val_mask]\n",
    "y_val_np = y[val_mask]\n",
    "\n",
    "\n",
    "X_train_np = torch.tensor(X, dtype=torch.float32)\n",
    "y_train_np = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "X_val_np = torch.tensor(X_val_np, dtype=torch.float32)\n",
    "y_val_np = torch.tensor(y_val_np, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11e9d3b-797a-44f3-a4a2-3fdeb435009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets save the files once \n",
    "np.save(\"../data/X_train.npy\", X_train)\n",
    "np.save(\"../data/y_train.npy\", y_train)\n",
    "np.save(\"../data/X_val.npy\", X_val)\n",
    "np.save(\"../data/y_val.npy\", y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfbc534-28f3-416e-ba04-207103589d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"../data/X_train.npy\")\n",
    "y_train = np.load(\"../data/X_train.npy\")\n",
    "X_val = np.load(\"../data/X_train.npy\")\n",
    "y_val = np.load(\"../data/X_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b421ed00-fbb9-4374-a17a-2d95f25402a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Creating Dataloaders \u001b[39;00m\n\u001b[1;32m      3\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m EEGDataset(X_train, y_train)\n\u001b[0;32m----> 4\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m EEGDataset(\u001b[43mX_val\u001b[49m, y_val)\n\u001b[1;32m      6\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m val_loader   \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset,   batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_val' is not defined"
     ]
    }
   ],
   "source": [
    "#Creating Dataloaders \n",
    "\n",
    "train_dataset = EEGDataset(X_train, y_train)\n",
    "val_dataset = EEGDataset(X_val, y_val)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e2bec-6a88-4f51-a8e7-886574f989b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a0a39a-01c4-4250-bb56-3dc86f6612ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#letting the computer know what piece of hardware to run the training \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17573ec-2d23-4640-969d-9a8d949a5848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model,loss and optimizer \n",
    "\n",
    "model = ResNet1D(n_channels=X_train.shape[1], n_classes=2).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2ce2b0-c52d-4157-8d8e-375695b232aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training loop\n",
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()  # put model in \"training mode\"\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        logits = model(X)\n",
    "\n",
    "        # 2. Compute loss\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        # 3. Zero out old gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track training accuracy & loss\n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "        _, predicted = torch.max(logits, dim=1)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d89e14-74fc-4123-8d07-9fbf4abd071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valid loop with no gradient Updates \n",
    "# Very similar to the training loop, except this one sets the model to eval and its accompanied by other\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()  # evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Do NOT track gradients\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            logits = model(X)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            running_loss += loss.item() * X.size(0)\n",
    "            _, predicted = torch.max(logits, dim=1)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    val_loss = running_loss / total\n",
    "    val_acc = correct / total\n",
    "\n",
    "    return val_loss, val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e870f0e-8619-45f6-9c37-a4702d08b9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#epich just refers to a com[lete pass throught of the dataset \n",
    "\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader, criterion, optimizer, device\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc = validate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d593fce-3c5c-4d92-8346-df68486fe2c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Saving for Saliency later\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet_eeg.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Can be loaded with the following code \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# model.load_state_dict(torch.load(\"resnet_eeg.pth\"))\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Saving for Saliency later\n",
    "torch.save(model.state_dict(), \"resnet_eeg.pth\")\n",
    "# Can be loaded with the following code \n",
    "# model.load_state_dict(torch.load(\"resnet_eeg.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aabe9d-3ac9-4a8e-b8a7-f62b60603bac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
